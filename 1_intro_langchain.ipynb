{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f55fdd8",
   "metadata": {},
   "source": [
    "# Intro to LangChain\n",
    "LangChain is a popular framework that allows you to quickly build applications and pipelines of Large Language Models (LLMs). You can use it to create chatbots, RAGs, agents and much more.\n",
    "\n",
    "The main idea of the library is that we can create a _chain_ of different components to create more complex applications. These _chains_ (you can think of them as pipelines) can be made up of various components such as:\n",
    "- **Prompts templates**: Prompts templates are templates to generate different type of prompts. Like chat prompts, question answering prompts, etc.\n",
    "- **LLMs**: Large Language Models are the core of LangChain. You can use any LLM that is compatible with the library, like OpenAI, Hugging Face, LLama, etc.\n",
    "- **Tools**: Tools are functions that can be used by the LLM to perform specific tasks. For example, you can use a tool to search the web, or to access a database.\n",
    "- **Agents**: Agents are components that can use LLMs and tools to perform specific tasks. They can be used to create chatbots, **R**etrieval **A**ugumentation **G**eneration (RAGs), etc.\n",
    "- **Retrievers**: Retrievers are components that can be used to retrieve information from a database or a knowledge base. They can be used to create RAGs, or to retrieve information from a database.  \n",
    "- **Memory**: Memory is a component that can be used to store information about the conversation. It can be used to create chatbots that can remember previous conversations, or to create RAGs that can remember previous queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f782a95",
   "metadata": {},
   "source": [
    "## Using LLMs in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d041d",
   "metadata": {},
   "source": [
    "LangChain supports a wide range of providers for LLMs, including OpenAI, Hugging Face, Groq,  LLama and many others.\n",
    "\n",
    "Let's start our exploration of LangChain by using Grog integration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb61e82",
   "metadata": {},
   "source": [
    "### Groq Integration\n",
    "Groq is a provider of LLMs that offers high-performance inference capabilities. To use Groq with LangChain, you need to set up your API key in the `.env` file. Follow the steps in the README.md file to set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80c0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9b45a",
   "metadata": {},
   "source": [
    "#### Load Credentials from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8777880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdf171",
   "metadata": {},
   "source": [
    "#### Defining the LLM (Using Groq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f8df8",
   "metadata": {},
   "source": [
    "We can define the LLM using the [`ChatGroq`](https://python.langchain.com/docs/integrations/chat/groq/) class from the `langchain_groq` module. \n",
    "This class allows us to specify:\n",
    "+ the model - below we use `llama-3.1-8b-instant`\n",
    "+ the temperature - we set it to `0.1` for more deterministic responses\n",
    "+ the maximum tokens - we set it to `512` to limit the response length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e42b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad1d0",
   "metadata": {},
   "source": [
    "#### Build prompt template\n",
    "A prompt is a set of instructions or input provided by a user to an LLM to guide its response. It helps the model understand the context and generate relevant output. In LangChain, we can create a prompt template using the `PromptTemplate` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e470ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for nutrition assistand\n",
    "\n",
    "template_na = \"\"\"You are a nutrition assistant.\n",
    "\n",
    "Task: Estimate calories and macros for the meal described.\n",
    "If details are missing, ask up to 3 clarifying questions.\n",
    "\n",
    "Meal: {meal}\n",
    "\n",
    "Return in this format:\n",
    "- Estimate: calories, protein_g, carbs_g, fat_g\n",
    "- Assumptions:\n",
    "- Clarifying questions:\n",
    "\"\"\"\n",
    "prompt_na = PromptTemplate(template=template_na, input_variables=[\"meal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ddde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c0a9d",
   "metadata": {},
   "source": [
    "The __input_variables__ are defined in the template using curly braces '{}'. This allows us to dynamically insert values into the template when we use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884340c",
   "metadata": {},
   "source": [
    "#### Define Chain\n",
    "A chain is sequence of components that are executed in order to produce a final output. In LangChain, we can use the pipe symbol `|` to define a chain of components. The output of one component is passed as input to the next component in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6cc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c947f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_na = prompt_na | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b708f0f",
   "metadata": {},
   "source": [
    "#### Invoke the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2eb6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_na = \"A family portion of wheat noodles, mixed with lentil noodles and a full glass of arrabiata sauce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61548c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_na = chain_na.invoke(input={\"meal\": question_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c56bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Estimate: \n",
      "  I'll need more information to provide an accurate estimate. However, I can make some assumptions based on average values.\n",
      "\n",
      "Assuming a family portion is around 400-500g of noodles and 250-300g of arrabiata sauce, here's a rough estimate:\n",
      "\n",
      "- Estimate: 1200-1500 calories, 20-25g protein, 150-200g carbs, 20-25g fat\n",
      "\n",
      "- Assumptions:\n",
      "  - Wheat noodles: 150-200g per 100g serving (approx. 350-400 calories, 7-8g protein, 70-80g carbs, 2-3g fat)\n",
      "  - Lentil noodles: 100-150g per 100g serving (approx. 200-300 calories, 10-12g protein, 30-40g carbs, 2-3g fat)\n",
      "  - Arrabiata sauce: 100-150 calories per 100g serving (approx. 10-15g fat, 2-3g protein, 10-15g carbs)\n",
      "\n",
      "- Clarifying questions:\n",
      "1. What is the exact weight of the noodles (wheat and lentil combined)?\n",
      "2. Is the arrabiata sauce homemade or store-bought?\n",
      "3. Are there any additional ingredients in the meal (e.g., vegetables, meat, cheese)?\n"
     ]
    }
   ],
   "source": [
    "print(answer_na.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e07785",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the backpropagation algorithm?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c1daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke(input={\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c5f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Backpropagation Algorithm**\n",
      "\n",
      "The backpropagation algorithm is a widely used method for training artificial neural networks (ANNs). It is an optimization technique used to minimize the error between the network's predictions and the actual output. The algorithm is based on the concept of gradient descent, which iteratively adjusts the network's weights and biases to reduce the error.\n",
      "\n",
      "**How Backpropagation Works**\n",
      "\n",
      "Here's a step-by-step explanation of the backpropagation algorithm:\n",
      "\n",
      "1. **Forward Pass**: The network processes the input data, and the output is calculated using the current weights and biases.\n",
      "2. **Error Calculation**: The difference between the predicted output and the actual output is calculated, which is known as the error.\n",
      "3. **Backward Pass**: The error is propagated backwards through the network, and the gradients of the error with respect to each weight and bias are calculated.\n",
      "4. **Weight Update**: The weights and biases are updated using the gradients and a learning rate, which is a small value that controls how quickly the network learns.\n",
      "5. **Repeat**: Steps 1-4 are repeated until the network converges or a stopping criterion is reached.\n",
      "\n",
      "**Mathematical Formulation**\n",
      "\n",
      "Let's denote the network's output as `y`, the actual output as `y_true`, and the error as `E`. The backpropagation algorithm can be mathematically formulated as follows:\n",
      "\n",
      "1. **Forward Pass**:\n",
      "   - `y = f(x, w, b)`\n",
      "   - `E = (y - y_true)^2`\n",
      "\n",
      "2. **Backward Pass**:\n",
      "   - `dE/dy = 2(y - y_true)`\n",
      "   - `dE/dw = dE/dy * dy/dw`\n",
      "   - `dE/db = dE/dy * dy/db`\n",
      "\n",
      "3. **Weight Update**:\n",
      "   - `w_new = w_old - learning_rate * dE/dw`\n",
      "   - `b_new = b_old - learning_rate * dE/db`\n",
      "\n",
      "**Example Use Case**\n",
      "\n",
      "Backpropagation is widely used in various applications, including:\n",
      "\n",
      "* Image classification\n",
      "* Speech recognition\n",
      "* Natural language processing\n",
      "* Time series forecasting\n",
      "\n",
      "For example, in image classification, the network processes an input image, and the output is a class label. The error is calculated as the difference between the predicted class label and the actual class label. The backpropagation algorithm is then used to update the network's weights and biases to minimize the error.\n",
      "\n",
      "**Code Example**\n",
      "\n",
      "Here's a simple example of\n"
     ]
    }
   ],
   "source": [
    "print(answer.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3203d797",
   "metadata": {},
   "source": [
    "If we'd like to ask multiple questions we can by passing a list of dictionary objects, where the dictionaries must contain the input variable set in our prompt template (\"question\") that is mapped to the question we'd like to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c306b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [ \n",
    "    {\"question\": \"What is the backpropagation algorithm?\"},\n",
    "    {\"question\": \"What is the purpose of the activation function in a neural network?\"},\n",
    "    {\"question\": \"What is the difference between supervised and unsupervised learning?\"},\n",
    "    {\"question\": \"Explain the concept of overfitting in machine learning.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a4f0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = chain.batch(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "722097ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Question: What is the backpropagation algorithm?\n",
      "Answer: **Backpropagation Algorithm**\n",
      "\n",
      "The backpropagation algorithm is a widely used method for training artificial neural networks. It is an optimization technique used to minimize the error between the network's predictions and the actual output.\n",
      "\n",
      "**How Backpropagation Works**\n",
      "\n",
      "The backpropagation algorithm works as follows:\n",
      "\n",
      "1. **Forward Pass**: The network processes the input data and produces an output.\n",
      "2. **Error Calculation**: The difference between the predicted output and the actual output is calculated, resulting in an error value.\n",
      "3. **Backward Pass**: The error value is propagated backwards through the network, adjusting the weights and biases of each layer to minimize the error.\n",
      "4. **Weight Update**: The weights and biases are updated based on the error gradient, using an optimization algorithm such as stochastic gradient descent (SGD).\n",
      "\n",
      "**Key Components of Backpropagation**\n",
      "\n",
      "1. **Activation Functions**: Used to introduce non-linearity into the network, allowing it to learn complex relationships between inputs and outputs.\n",
      "2. **Error Gradient**: The derivative of the error with respect to each weight and bias, used to update the network's parameters.\n",
      "3. **Optimization Algorithm**: Used to update the network's parameters based on the error gradient.\n",
      "\n",
      "**Advantages of Backpropagation**\n",
      "\n",
      "1. **Efficient**: Backpropagation is a computationally efficient algorithm, making it suitable for large-scale neural networks.\n",
      "2. **Effective**: Backpropagation can learn complex relationships between inputs and outputs, making it a popular choice for many machine learning tasks.\n",
      "3. **Flexible**: Backpropagation can be used with a variety of activation functions and optimization algorithms, making it a versatile technique.\n",
      "\n",
      "**Common Applications of Backpropagation**\n",
      "\n",
      "1. **Image Classification**: Backpropagation is widely used in image classification tasks, such as object detection and image segmentation.\n",
      "2. **Natural Language Processing**: Backpropagation is used in NLP tasks, such as language modeling and sentiment analysis.\n",
      "3. **Time Series Prediction**: Backpropagation is used in time series prediction tasks, such as stock price prediction and weather forecasting.\n",
      "\n",
      "**Example Code**\n",
      "\n",
      "Here is an example of backpropagation implemented in Python using the Keras library:\n",
      "```python\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
      "model.add(Dense(32, activation='relu'))\n",
      "model.add(Dense(10, activation='softmax'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: What is the purpose of the activation function in a neural network?\n",
      "Answer: The primary purpose of the activation function in a neural network is to introduce non-linearity into the model. This is crucial because without non-linearity, a neural network would essentially be a linear model, which is not capable of learning complex relationships between inputs and outputs.\n",
      "\n",
      "In a neural network, each node (or neuron) applies a weighted sum of its inputs, followed by an activation function. The activation function takes the weighted sum and maps it to a new value, which is then passed on to the next layer.\n",
      "\n",
      "The activation function serves several purposes:\n",
      "\n",
      "1. **Introduces non-linearity**: As mentioned earlier, this is the primary purpose of the activation function. It allows the neural network to learn non-linear relationships between inputs and outputs.\n",
      "2. **Helps prevent overfitting**: By introducing non-linearity, the activation function helps prevent the neural network from overfitting to the training data.\n",
      "3. **Allows for complex decision boundaries**: The activation function enables the neural network to learn complex decision boundaries, which is essential for many machine learning tasks.\n",
      "4. **Helps with gradient flow**: The activation function can help with gradient flow by introducing a non-linear transformation of the input, which can make it easier for the network to learn.\n",
      "\n",
      "Some common activation functions used in neural networks include:\n",
      "\n",
      "* Sigmoid (logistic) function\n",
      "* ReLU (Rectified Linear Unit)\n",
      "* Tanh (hyperbolic tangent)\n",
      "* Leaky ReLU\n",
      "* Softmax\n",
      "\n",
      "In summary, the activation function is a crucial component of a neural network, and its purpose is to introduce non-linearity, prevent overfitting, allow for complex decision boundaries, and help with gradient flow.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: What is the difference between supervised and unsupervised learning?\n",
      "Answer: The primary difference between supervised and unsupervised learning lies in the type of data used for training and the goal of the learning process.\n",
      "\n",
      "**Supervised Learning:**\n",
      "\n",
      "In supervised learning, the algorithm is trained on labeled data, where each example is associated with a target output or response variable. The goal is to learn a mapping between the input data and the target output, so the algorithm can make predictions on new, unseen data. The algorithm is \"supervised\" by the labeled data, which provides feedback on its performance.\n",
      "\n",
      "Example: Image classification, where the algorithm is trained on labeled images of cats and dogs, and then predicts the class of a new, unseen image.\n",
      "\n",
      "**Unsupervised Learning:**\n",
      "\n",
      "In unsupervised learning, the algorithm is trained on unlabeled data, and the goal is to discover patterns, relationships, or structure in the data. The algorithm does not receive any feedback on its performance, as there is no target output to compare against.\n",
      "\n",
      "Example: Clustering, where the algorithm groups similar customers based on their purchasing behavior, without any prior knowledge of the groups.\n",
      "\n",
      "Key differences:\n",
      "\n",
      "1. **Labeled vs. Unlabeled Data**: Supervised learning uses labeled data, while unsupervised learning uses unlabeled data.\n",
      "2. **Goal**: Supervised learning aims to make predictions, while unsupervised learning aims to discover patterns or structure.\n",
      "3. **Feedback**: Supervised learning receives feedback on its performance, while unsupervised learning does not.\n",
      "\n",
      "In summary, supervised learning is used when you have labeled data and want to make predictions, while unsupervised learning is used when you have unlabeled data and want to discover patterns or structure.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Question: Explain the concept of overfitting in machine learning.\n",
      "Answer: **Overfitting in Machine Learning:**\n",
      "\n",
      "Overfitting is a common problem in machine learning where a model is too complex and learns the noise in the training data rather than the underlying patterns. As a result, the model performs well on the training data but poorly on new, unseen data.\n",
      "\n",
      "**Causes of Overfitting:**\n",
      "\n",
      "1. **Complex models**: Models with too many parameters or features can overfit the training data.\n",
      "2. **Small training datasets**: When the training dataset is small, the model may learn the noise in the data rather than the underlying patterns.\n",
      "3. **High variance**: Models with high variance are more prone to overfitting.\n",
      "\n",
      "**Consequences of Overfitting:**\n",
      "\n",
      "1. **Poor generalization**: The model performs poorly on new, unseen data.\n",
      "2. **High error rates**: The model has high error rates on new data.\n",
      "3. **Lack of robustness**: The model is not robust to changes in the data or the model itself.\n",
      "\n",
      "**Examples of Overfitting:**\n",
      "\n",
      "1. **Polynomial regression**: A polynomial regression model with a high degree may overfit the training data.\n",
      "2. **Decision trees**: A decision tree with too many splits may overfit the training data.\n",
      "3. **Neural networks**: A neural network with too many layers or too many neurons may overfit the training data.\n",
      "\n",
      "**Solutions to Overfitting:**\n",
      "\n",
      "1. **Regularization**: Techniques such as L1 and L2 regularization can reduce the complexity of the model.\n",
      "2. **Early stopping**: Stopping the training process when the model's performance on the validation set starts to degrade.\n",
      "3. **Data augmentation**: Increasing the size of the training dataset by applying transformations to the existing data.\n",
      "4. **Cross-validation**: Evaluating the model's performance on multiple subsets of the data to prevent overfitting.\n",
      "5. **Simplifying the model**: Reducing the number of parameters or features in the model.\n",
      "\n",
      "**Code Example:**\n",
      "\n",
      "Here's an example of overfitting in Python using scikit-learn:\n",
      "```python\n",
      "from sklearn.datasets import make_regression\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Generate a regression dataset\n",
      "X, y = make_regression(n_samples=100, n_features=10, noise=0.1)\n",
      "\n",
      "# Split the data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(qs, answers):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Question: {question['question']}\")\n",
    "    print(f\"Answer: {answer.content.strip()}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05701d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
